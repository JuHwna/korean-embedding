{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3단원 code summary.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VaFG9SV8h5lU",
        "colab_type": "text"
      },
      "source": [
        "이 파일은 colab 기준의 코드입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogJaQf3hQn3Q",
        "colab_type": "text"
      },
      "source": [
        "# Colab 기준 Konlpy 설치\n",
        " - 최근 mecab 오류로 pip install konlpy로만 설치하면 안 된다.\n",
        " - 그래서 sh 파일까지 불러와야 한다고 한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRTR-AMZQor4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get update\n",
        "!apt-get install g++ openjdk-8-jdk \n",
        "!pip3 install konlpy JPype1-py3\n",
        "!bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)\n",
        "import jpype\n",
        "p=jpype.getDefaultJVMPath()\n",
        "jpype.startJVM(p)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSrCMuPJz7ET",
        "colab_type": "text"
      },
      "source": [
        "# 형태소 사전기 충돌 현상\n",
        " - mecab 오류로 위의 코드로 실행한 결과, mecab 이외의 형태소 사전기가 오류 뜨는 현상 발견\n",
        " - 원인을 찾으려고 했으나 찾지 못했고 어떤 분께서 아마 충돌 때문에 일어나는 원인이라고 함\n",
        " - 그래서 한 번 런타임을 끊고 기본 코드를 실행해보았음\n",
        " \n",
        " from konlpy.tag import Okt\n",
        " \n",
        " okt=Okt()\n",
        "\n",
        " - 그 결과 제대로 작동하는 것을 확인, 하지만 mecab은 제대로 작동하지 않음 \n",
        " - 그래서 결론은 그냥 mecab용 따로 열고 그 이외의 용을 따로 열어서 하는 것이 맞다고 판단합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLqNlqoKz7Y_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install konlpy\n",
        "import konlpy\n",
        "import jpype\n",
        "p=jpype.getDefaultJVMPath()\n",
        "jpype.startJVM(p)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEoNlx42Q6tx",
        "colab_type": "text"
      },
      "source": [
        "## KorQuAD 코드 구현 방법\n",
        " - 전처리 과정을 직접 해보고 싶은 분들이라면 korquad 원본 파일을 가지고 와야 한다.\n",
        " - 저자의 사이트에 들어가면 json파일이 있는데 웹사이트 창에서만 볼 수 있고 다운이 안 되는 모습을 볼 수 있다.\n",
        " - 이 점을 해결하기 위해선 링크로 가지고 오는 방식을 취해야 한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dN5O9qCKQo2s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "url = 'https://korquad.github.io/dataset/KorQuAD_v1.0_train.json'\n",
        "data = requests.get(url).json()\n",
        "corpus_fname=data\n",
        "\n",
        "# 그 밑의 코드인 open(corpus_fname,'r', encoding='utf-8) as f1을 지워야 한다."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WEWnDnsSgkc",
        "colab_type": "text"
      },
      "source": [
        "# 네이버 영화 리뷰 코드 구현 방법\n",
        " - 전처리 과정을 직접 해보고 싶은 분들이라면 네이버 영화 리뷰 학습 데이터셋을 가지고 와야 한다.\n",
        " - 깃허브에 txt 파일이 있긴 한데 저자의 사이트에는 웹 상에 txt 파일로 창이 뜨는 것을 확인할 수 있다.\n",
        "   - 깃허브에서 다운 받아 구글드라이브에 넣고 연결해서 돌려도 상관 없다.\n",
        "   - 하지만 링크로 다운받아서 돌리고 싶을 때 위의 방식대로 가져오는 방법이 있다 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41ayx3moS-r5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "url = 'https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt'\n",
        "data = requests.get(url)\n",
        "corpus_fname=data.text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIhXDvL3RstS",
        "colab_type": "text"
      },
      "source": [
        "### Mecab 매개변수\n",
        " - morphs(phrase) : 문체를 형태소로 구문 분석합니다.\n",
        " \n",
        " (ex)'아버지','가','방','에','들어가','신다.'\n",
        " - nouns(phrase) : 명사 추출기.\n",
        " \n",
        " (ex)'아버지', '방'\n",
        " - pos(phrase, flatten=True)\n",
        " \n",
        " (ex) ('아버지', 'NNG'),('가', 'JKS'),('방', 'NNG'),('에', 'JKB'),('들어가', 'VV'),('신다', 'EP+EC')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heLgSy9d1Bdg",
        "colab_type": "text"
      },
      "source": [
        "## Hannanum 매개변수\n",
        " - analyze(phrase) : 각 토큰의 다양한 형태학적 후보(?)를 반환합니다.\n",
        "\n",
        "    - 사전 검색\n",
        "    - 분류되지 않는 용어 세분화\n",
        "\n",
        " (ex) [('아버지가방에들어가', 'ncn'), ('이', 'jp'), ('시', 'ep'), ('ㄴ다', 'ef')],\n",
        "  [('아버지가방에들어가신다', 'ncn')]\n",
        "\n",
        " - morphs\n",
        "\n",
        " (ex) ['아버지가방에들어가', '이', '시ㄴ다']\n",
        " \n",
        " - nouns\n",
        "\n",
        " (ex) ['아버지가방에들어가']\n",
        "\n",
        " - pos\n",
        "\n",
        "  (ex) [('아버지가방에들어가', 'N'), ('이', 'J'), ('시ㄴ다', 'E')]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWtDDmnn1Bm0",
        "colab_type": "text"
      },
      "source": [
        "## Kkma 매개 변수\n",
        " - morphs\n",
        "\n",
        " (ex) ['아버지', '가방', '에', '들어가', '시', 'ㄴ다']\n",
        "\n",
        " - nouns\n",
        "\n",
        " (ex) ['아버지', '아버지가방', '가방']\n",
        "\n",
        " - pos\n",
        "\n",
        " (ex) [('아버지', 'NNG'),\n",
        " ('가방', 'NNG'),\n",
        " ('에', 'JKM'),\n",
        " ('들어가', 'VV'),\n",
        " ('시', 'EPH'),\n",
        " ('ㄴ다', 'EFN')]\n",
        "\n",
        " - sentences(phrase) : 문장 탐지\n",
        "\n",
        " (ex) ['아버지가방에 들어가신다']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2SRo8Nl1Bx1",
        "colab_type": "text"
      },
      "source": [
        "## Komoran 매개변수\n",
        " - morphs\n",
        "\n",
        " (ex) ['아버지', '가방', '에', '들어가', '시', 'ㄴ다']\n",
        " \n",
        " - nouns\n",
        "\n",
        " (ex) ['아버지', '가방']\n",
        "\n",
        " - pos\n",
        "\n",
        "  (ex) [('아버지', 'NNG'),\n",
        " ('가방', 'NNP'),\n",
        " ('에', 'JKB'),\n",
        " ('들어가', 'VV'),\n",
        " ('시', 'EP'),\n",
        " ('ㄴ다', 'EC')]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ma6Fu7OP7AkV",
        "colab_type": "text"
      },
      "source": [
        "## Okt 매개변수 (전 Twitter)\n",
        " - morphs\n",
        "\n",
        " (ex) ['아버지', '가방', '에', '들어가신다']\n",
        " \n",
        " - nouns\n",
        "\n",
        " (ex) ['아버지', '가방']\n",
        "\n",
        " - pos\n",
        "\n",
        "  (ex) [('아버지', 'Noun'), ('가방', 'Noun'), ('에', 'Josa'), ('들어가신다', 'Verb')]\n",
        "\n",
        "  - phrases : 문구 추출기\n",
        "\n",
        "  (ex) ['아버지가방', '아버지', '가방']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJM_xmwe7hht",
        "colab_type": "text"
      },
      "source": [
        "---------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWYv7o3x7kAa",
        "colab_type": "text"
      },
      "source": [
        "# 정규표현식 기본 정리\n",
        "\n",
        "|특수 기호|의미|\n",
        "|-----------|----|\n",
        "|()|문자열을 묶음 처리할 때 사용|\n",
        "|[a-z]|영문자 중 소문자에 해당하는 a부터 z까지의 문자열|\n",
        "|[A-Z]|영문자 중 대문자에 해당하는 A부터 Z까지의 문자열|\n",
        "|[0-9]|0~9 사이의 문자 중 하나|\n",
        "|[가-힣|가,힣 사이의 모든 문자|\n",
        "|^|텍스트의 시작지점|\n",
        "|$|텍스트의 종료지점|\n",
        "|?|앞의 문자가 0번 또는 1번만 등장|\n",
        "|+|앞의 문자가 1번 이상 등장|\n",
        "|*|앞의 문자가 0번 이상 등장|\n",
        "|{n}|앞의 문자가 n번 등장|\n",
        "|{m,n}|앞의 문자가 m-n번 등장|\n",
        "|(a\\|b)|a 또는 b|\n",
        "|[문자들]|대괄호 속의 문자 중 하나|\n",
        "|[^문자들|대괄호 속의 문자가 아닌 문자 하나|\n",
        "|.|개행 문자를 제외한 아무 문자 하나|\n",
        "|\\\\\\\\|백슬래시|\n",
        "|\\\\d==[0-9]|모든 숫자|\n",
        "|\\\\D==[^0-9]|숫자 외의 문자|\n",
        "|\\\\s==[ \\\\t\\\\n\\\\r\\\\f\\\\v]|공백 문자|\n",
        "|\\\\S==[^ \\\\t\\\\n\\\\r\\\\f\\\\v]|공백 문자 외의 문자|\n",
        "|\\\\w==[가-힣a-zA-Z0-9_]|숫자,알파벳,한글 등|\n",
        "|\\\\W==[^가-힣a-zA-Z0-9_]|문자 외의 기호|"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6fkD7Cz7kFI",
        "colab_type": "text"
      },
      "source": [
        "## 정규표현식 긴 패턴\n",
        "\n",
        "1. 유효한 Email 주소 검사\n",
        " - 목표 \n",
        "    - user명(@ 왼쪽 편에 있는 모든 것)은 대문자 또는 소문자와 숫자, '.','-','_'로 구성\n",
        "    -  .로 시작하거나 끝나지 않아야 함, 또한 ..와 같이 반복되면 안됨, 공백이 있으면 안됨\n",
        "    - \"@\" 부분 골뱅이\n",
        "    - server 명(나머지 부분)은 대문자 또는 소문자와 숫자, '.','_'로 구성\n",
        "    - .로 시작하거나 끝나지 않아야 함, 또한 ..와 같이 반복되면 안됨, 공백이 있으면 안됨\n",
        "\n",
        " - '^[a-zA-Z0-9+-_.]+@[a-zA-Z0-9-]+\\\\.[a-zA-Z0-9-.]+$' 의미 분석\n",
        "\n",
        "|패턴 검사|의미|\n",
        "|---------|----|\n",
        "|^[a-zA-Z0-9+-_.]+@|이메일에서 @을 기준으로 계정을 나타내며 앞에 ^가 붙었으므로 계정이 맨 앞에 오는지 판단|\n",
        "||[a-zA-Z0-9+-_.]+와 같이 영문 대소문자, 숫자, +, -, _, .으로 되어 있어야 하고 문자 1개 이상인지 판단|\n",
        "|[a-zA-Z0-9-]+|영문 대소문자, 숫자, -이면서 문자 1개 이상인지 판단|\n",
        "|\\\\.|중간에 \\.를 넣어서 도메인.최상위도메인 형식인지 판단|\n",
        "\n",
        "\n",
        "2. URL 패턴 검사\n",
        " - ((ftp|http|https):\\/\\/)?(www.)?(?!.*(ftp|http|https|www.))[a-zA-Z0-9_-]+(\\.[a-zA-Z]+)+((\\/)[\\w#]+)*(\\/\\w+\\?[a-zA-Z0-9_]+=\\w+(&[a-zA-Z0-9_]+=\\w+)*)?$ 의미 분석\n",
        "   - (ftp|http|https):\\/\\/)? : 앞에 ftp://나 http://, https:// 가 있을 수도 있기 때문에 ?를 붙임\n",
        "   - (www.)? : www.가 있을 수도 있으니 ?를 붙임\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuSyvVRw-Wgl",
        "colab_type": "text"
      },
      "source": [
        "# re 함수 정리\n",
        "\n",
        "|Method|목적|\n",
        "|------|----|\n",
        "|compile|정규식 패턴을 입력으로 받아들여 정규식 객체를 리턴|\n",
        "|match(pattern, string)|문자열의 처음부터 정규식과 매치되는지 조사함|\n",
        "|search(pattern, string)|문자열 임의 지점을 검색하여 정규식과 매치되는지 조사함|\n",
        "|fullmatch(pattern, string)|문자열 전체 지점을 검색하여 정규식과 매치되는지 조사함|\n",
        "|sub(pattern, repl, string)|string에서 pattern과 매치하는 텍스트를 repl로 치환한다|\n",
        "|split(pattern, string)|string을 pattern을 기준으로 나눈다|\n",
        "|findall|정규식과 매치되는 모든 문자열을 리스트로 돌려줌|\n",
        "|finditer|정규식과 매치되는 모든 문자열을 반복 가능한 객체로 돌려줌|\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "830M3DelUmvO",
        "colab_type": "text"
      },
      "source": [
        "# khaiii 형태소  분석기 설치하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFC6tX5-RtOI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/kakao/khaiii.git\n",
        "\n",
        "!pip install cmake\n",
        "\n",
        "!mkdir build\n",
        "\n",
        "!cd build && cmake /content/khaiii\n",
        "\n",
        "!cd /content/build/ && make all\n",
        "\n",
        "!cd /content/build/ && make resource\n",
        "\n",
        "!cd /content/build && make install\n",
        "\n",
        "!cd /content/build && make package_python\n",
        "\n",
        "!pip install /content/build/package_python"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDmxzbWLRtZa",
        "colab_type": "code",
        "outputId": "09f6ecad-d575-4567-d7ae-67a90f7ee785",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from khaiii import KhaiiiApi\n",
        "tokenizer=KhaiiiApi()\n",
        "data=tokenizer.analyze(\"아버지가방에들어가신다\")\n",
        "tokens=[]\n",
        "for word in data:\n",
        "  tokens.extend([str(m).split(\"/\")[0] for m in word.morphs])\n",
        "tokens"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['아버지', '가', '방', '에', '들어가', '시', 'ㄴ다']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3ju6anbYqmj",
        "colab_type": "code",
        "outputId": "2216c3e4-3a52-48a6-bd11-18dd2bcb9258",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "data=tokenizer.analyze(\"아버지가방에들어가신다\")\n",
        "tokens=[]\n",
        "for word in data:\n",
        "  tokens.extend([str(m) for m in word.morphs])\n",
        "tokens"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['아버지/NNG', '가/JKS', '방/NNG', '에/JKB', '들어가/VV', '시/EP', 'ㄴ다/EC']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHzArkH2Zdra",
        "colab_type": "text"
      },
      "source": [
        "# 비지도 학습 기반 형태소분석"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5D4JrPqZhAo",
        "colab_type": "text"
      },
      "source": [
        "## soynlp 형태소 분석기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJAXfVATS8gl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7SBvIArZ75u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install soynlp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5Tw_mW5Kwmb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "f84a1ca7-0400-41db-ef48-afd85cefed87"
      },
      "source": [
        "from soynlp.word import WordExtractor\n",
        "import requests\n",
        "import math\n",
        "import pandas as pd\n",
        "from soynlp.tokenizer import LTokenizer\n",
        "corpus_fname = '/gdrive/My Drive/ratings.txt'\n",
        "sentences= [sent.strip() for sent in open(corpus_fname,'r').readlines()]\n",
        "word_extractor=WordExtractor(min_frequency=100,min_cohesion_forward=0.05,min_right_branching_entropy=0.0)\n",
        "word_extractor.train(sentences)\n",
        "words = word_extractor.extract()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training was done. used memory 5.327 Gb\n",
            "all cohesion probabilities was computed. # words = 7247\n",
            "all branching entropies was computed # words = 188449\n",
            "all accessor variety was computed # words = 188449\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQeICKGbbeVO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "305850d6-26bf-435b-ea07-34dc0c60c6e2"
      },
      "source": [
        "import math\n",
        "from soynlp.tokenizer import LTokenizer\n",
        "scores=word_extractor.word_scores()\n",
        "scores={key:(scores[key].right_branching_entropy) for key in scores.keys()}\n",
        "tokenizer=LTokenizer(scores=scores)\n",
        "tokens=tokenizer.tokenize('애비는 종이었다')\n",
        "tokens"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "all cohesion probabilities was computed. # words = 7247\n",
            "all branching entropies was computed # words = 188449\n",
            "all accessor variety was computed # words = 188449\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['애비는', '종이었다']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkC-AoxYSxvZ",
        "colab_type": "text"
      },
      "source": [
        "학습시켰으나 왜 나누지 못하는지에 대해서 알지 못했음...."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPSVhB_creM8",
        "colab_type": "text"
      },
      "source": [
        "## 구글 센텐스피스"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3ODeuNFrsY6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "09a028bc-069e-4adf-bc1e-06ef29dc85f3"
      },
      "source": [
        "!pip install sentencepiece"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (0.1.85)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2i2n4mFeriO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file=open('/gdrive/My Drive/processed_wiki_ko.txt','r')\n",
        "\n",
        "lines=file.read()\n",
        "\n",
        "file.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPFFs6vujI-7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "15eff5ae-e9ec-4115-af4e-c8fb7e8a3f50"
      },
      "source": [
        "import sentencepiece as spm\n",
        "parameter='--input={} --model_prefix={} --vocab_size={} --user_defined_symbols={}'\n",
        "input_file=lines\n",
        "vocab_size=32000\n",
        "prefix='bert_kor'\n",
        "user_defined_symbols = '[PAD],[UNK],[CLS],[SEP],[MASK]'\n",
        "cmd=parameter.format(input_file,prefix,vocab_size,user_defined_symbols)\n",
        "spm.SentencePieceTrainer.Train(cmd)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-82-4e24b0beba60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0muser_defined_symbols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'[PAD],[UNK],[CLS],[SEP],[MASK]'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparameter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0muser_defined_symbols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mspm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSentencePieceTrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m: Not found: unknown field name \"얼\" in TrainerSpec."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zP9fBSnghj8c",
        "colab_type": "text"
      },
      "source": [
        "어디서 에러가 뜨긴 하는데 잡지를 못하겠따...."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdlBgA22c9hu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "outputId": "e1812b53-c409-408e-946c-8bf02d495b0a"
      },
      "source": [
        "!pip install bert-tensorflow"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bert-tensorflow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/66/7eb4e8b6ea35b7cc54c322c816f976167a43019750279a8473d355800a93/bert_tensorflow-1.0.1-py2.py3-none-any.whl (67kB)\n",
            "\r\u001b[K     |████▉                           | 10kB 21.4MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 30kB 2.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 40kB 1.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 51kB 2.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 61kB 2.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 2.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from bert-tensorflow) (1.12.0)\n",
            "Installing collected packages: bert-tensorflow\n",
            "Successfully installed bert-tensorflow-1.0.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "bert"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7EKYcWIcuE4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "c2377b24-48fa-4d66-ca8b-db991a885dbb"
      },
      "source": [
        "from bert.tokenization import FullTokenizer\n",
        "tokenizer=FullTokenizer(do_lower_case=False)\n",
        "tokenizer.tokenize(\"집에좀 가자\")"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-77-5a0ba8f90761>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbert\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenization\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFullTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFullTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo_lower_case\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"집에좀 가자\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'vocab_file'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwmabeXqhpE9",
        "colab_type": "text"
      },
      "source": [
        "bert 한국어 버전을 만든 사람에 따르면 구글 센텐스피스를 이용해 학습을 시켜 만든 vocab 파일을 이용해서 사용한다고 합니다. 그런데 현재 저것을 제대로 돌릴 수 없어 bert를 제대로 사용하지 못합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHXpW3coa-Xr",
        "colab_type": "text"
      },
      "source": [
        "## 띄어쓰기 교정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cApMWNhObT8h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "81597dd3-67ed-4cb9-e117-5e5f456faa68"
      },
      "source": [
        "!pip install soyspacing"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting soyspacing\n",
            "  Downloading https://files.pythonhosted.org/packages/66/30/2bcfe84f8cb41d0011ff6f430c47297e039054853ebc8906a8369594f776/soyspacing-1.0.17-py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from soyspacing) (1.17.5)\n",
            "Installing collected packages: soyspacing\n",
            "Successfully installed soyspacing-1.0.17\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UewCvugtrrML",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "86e979fb-a238-4fe3-954d-f253655a39c7"
      },
      "source": [
        "from soyspacing.countbase import CountSpace\n",
        "\n",
        "corpus_fname= '/gdrive/My Drive/ratings.txt'\n",
        "model=CountSpace()\n",
        "model.train(corpus_fname)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "all tags length = 200943 --> 200853, (num_doc = 200000)"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prRufogUagiT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5e406b02-a770-4aec-8c82-2d3879753c1d"
      },
      "source": [
        "model.correct(\"어릴때보고지금다시봐도재밌어요\")"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('어릴때 보고 지금 다시봐도 재밌어요', [0, 0, 1, 0, 1, 0, 1, 0, None, 0, 1, 0, 0, 0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    }
  ]
}